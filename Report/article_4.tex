%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Arsclassica Article
% LaTeX Template
% Version 1.1 (1/8/17)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Lorenzo Pantieri (http://www.lorenzopantieri.net) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
12pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
%twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
BCOR5mm, % Binding correction
]{scrartcl}
\usepackage{float}
\input{structure.tex} % Include the structure.tex file which specified the document structure and layout

\hyphenation{Fortran hy-phen-ation} % Specify custom hyphenation points in words with dashes where you would like hyphenation to occur, or alternatively, don't put any dashes in a word to stop hyphenation altogether

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{Article Title}} % The article title

%\subtitle{Subtitle} % Uncomment to display a subtitle

\author{\spacedlowsmallcaps{Fabrizio Cominetti, Davide Abete, Ruben Agazzi}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

\date{} % An optional date to appear under the author(s)
\usepackage{hyperref}
%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%	HEADERS
%----------------------------------------------------------------------------------------

\renewcommand{\sectionmark}[1]{\markright{\spacedlowsmallcaps{#1}}} % The header for all pages (oneside) or for even pages (twoside)
%\renewcommand{\subsectionmark}[1]{\markright{\thesubsection~#1}} % Uncomment when using the twoside option - this modifies the header on odd pages
\lehead{\mbox{\llap{\small\thepage\kern1em\color{halfgray} \vline}\color{halfgray}\hspace{0.5em}\rightmark\hfil}} % The header style

\pagestyle{scrheadings} % Enable the headers specified in this block

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS & LISTS OF FIGURES AND TABLES
%----------------------------------------------------------------------------------------

\maketitle % Print the title/author/date block

\setcounter{tocdepth}{2} % Set the depth of the table of contents to show sections and subsections only

\tableofcontents % Print the table of contents


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\section*{Abstract} % This section will not appear in the table of contents due to the star (\section*)

Il mondo Marvel è composto da numerosi fumetti, film e serie tv, in crescita numerica costante. Quest'ultimo è inoltre caratterizzato dalla presenza di un quantitativo enorme di personaggi.
Il progetto realizzato si pone dunque l'obiettivo di creare una base di dati contenente le relazioni fra i vari prodotti Marvel. All'interno del database sono presenti relazioni come ad esempio fra personaggi e fumetti, personaggi e personaggi, e numerose altre. Per la realizzazione di questo progetto è stato scelto un database non relazionale di tipologia a grafo, costruito tramite l'utilizzo della piattaforma Neo4j.

%----------------------------------------------------------------------------------------
%	AUTHOR AFFILIATIONS
%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------

\newpage % Start the article content on the second page, remove this if you have a longer abstract that goes onto the second page

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\section{Introduzione}
Il progetto ha avuto origine dall'idea di realizzare un ampio database relativo al mondo Marvel, una base di dati che permettesse di navigare al suo interno tra i vari prodotti Marvel, fra cui personaggi, film, serie tv e fumetti.
L'obiettivo del progetto è di ottenere una sorta di "rete sociale" di super-eroi o personaggi Marvel, i quali sono collegati ai rispettivi fumetti, film, serie tv in cui sono presenti, oppure ancora presentano i rispettivi collegamenti interpersonali fra personaggi ed altri personaggi.
Per questi motivi la scelta in fase di costruzione del progetto è ricaduta su un modello a grafo.
I dati sono stati ottenuti mediante l'utilizzo di API e web scraping, per arrivare alla costruzione del database tramite l'utilizzo della piattaforma open-source Neo4j.
Questo database conserva le principali caratteristiche ed i principali vantaggi dei modelli a grafo, e perciò un suo utilizzo futuro potrebbe essere quello di un sistema di raccomandazione.
% breve descrizione modelli a grafo e vantaggi
I database a grafo sono organizzati in un insieme di nodi e di relazioni tra i nodi (archi).
Nodi e archi possono avere proprietà, gli archi rappresentano le relazioni tra i nodi. I nodi possono rappresentare entità, le proprietà sono dati relativi ai nodi.
Tra le proprietà principali dei modelli a grafo troviamo la caratteristica 'schema free', infatti in un modello a grafo non esiste uno schema fisso in quanto posso rappresentare con un nodo più entità.
Una criticità dei modelli a grafo è che non scalano in modo efficace, perciò hanno una gestione dei dati inferiore rispetto ad altri modelli NoSQL.
Le applicazioni di questa tipologia sono numerose, come ad esempio social networks, sistemi di raccomandazione,
applicazioni geografiche, logistics networks, financial transaction graphs, master data management, bioinformatics,
authorization and access control, e molte altre.
 
%----------------------------------------------------------------------------------------
%	METHODS
%----------------------------------------------------------------------------------------

\section{Fonti dati}
Per l'ottenimento dei dati sono stati utilizzati due metodi diversi: l'utilizzo di una Web API e Web Scraping.
% breve descrizione API e web scraping
Le API, Application Programming Interface, sono protocolli utilizzati come interfaccia di comunicazione tra componenti software. Esse consistono in insiemi di routine, strutture dati o variabili che permettono al programmatore di richiamare le funzionalità di un’applicazione di terze parti. \cite{BigDataBook}
% cit libro
JSON (JavaScript Object Notation) è il formato con cui tipicamente le API rispondono. Questo formato è basato su due strutture: una collezione di coppie nomi/valore (objects) e una lista ordinata di valori (array). Spesso inoltre i file JSON hanno una struttura nidificata.
Lo scraping è il processo di estrarre dati da un sistema senza l'utilizzo di APIs. Lo scraping indica anche il processo di estrarre dati da pagine web.

\subsection{Web API}
Per l'ottenimento dei dati tramite web API è stato utilizzato il servizio fornito dalla Marvel, che mette a disposizione una sua web API gratuita per ottenere numerosi dati, tra cui quelli relativi a personaggi e fumetti.
L'ottenimento dei dati è avvenuto tramite esecuzione di un jupyter notebook ed il linguaggio di programmazione python.
Di seguito riassumiamo i principali passi di esecuzione del notebook:
\begin{enumerate}
\item Ottenimento dei dati dei personaggi in formato JSON tramite chiamata al relativo endpoint della web API a gruppi di 100 personaggi, in quanto corrisponde al limite imposto dagli sviluppatori del servizio.
\item Salvataggio su file CSV dei dati relativi ai personaggi ottenuti, in modo da eseguire successive manipolazioni facilmente tramite la libreria \textit{pandas}, prima di inserire i dati nel database.
\item Ottenimento dei dati dei fumetti in formato JSON tramite chiamata al relativo endpoint della web API a gruppi di 100 fumetti, in quanto corrisponde al limite imposto dagli sviluppatori del servizio.
\item Salvataggio su file CSV dei dati relativi ai fumetti ottenuti, in modo da eseguire successive manipolazioni facilmente tramite la libreria \textit{pandas}, prima di inserire i dati nel database.
\end{enumerate}
\subsection{Web Scraping}
Per la parte riguardante il Web Scraping come sorgente dati è stata utilizzata la Marvel Cinematic Universe Wiki. \cite{linkFandom}
Lo scraping è stato effettuato, anche in questo caso, tramite esecuzione di un jupyter notebook ed il linguaggio di programmazione python.
I principali passi eseguiti dal notebook per completare lo scraping sono i seguenti:
\begin{enumerate}
\item Ottenimento, dalla pagina relativa a tutti i personaggi della wiki, dei nomi dei personaggi con i relativi link alla pagina personale. 
\item Per ogni personaggio, aprendo la pagina personale, acquisizione sempre tramite scraping delle informazioni rilevanti, come ad esempio: biografia, lista di film in cui è presente il personaggio, lista di serie tv in cui è presente il personaggio e relazioni con altri personaggi.
\item Per ogni film trovato nelle pagine dei personaggi, selezionare la pagina relativa al film e ottenere tramite scraping le informazioni del film come ad esempio la trama, i registi, scrittori, compositori, incasso, data di uscita e durata del film.
\item Per ogni serie, trovata nelle pagine dei personaggi, aprire la pagina relativa alla serie ed ottenere tramite scraping le informazioni della serie in questione, come ad esempio la trama, i registi, i produttori e i compositori.
\item Salvataggio temporaneo all'interno di file CSV dei film, serie tv, personaggi ed altre informazioni ottenute per essere processati in seguito.
\end{enumerate}

\section{Data Exploration}
La fase di data exploration è stata realizzata sempre utilizzando python, tramite l'ausilio di alcune librerie grafiche per la creazione di visualizzazioni.

\subsection{Data Quality}
Le principali problematiche nella qualità dei dati sono state riscontrate nelle biografie dei personaggi e nelle relazioni tra i vari personaggi ottenute tramite web scraping.
\subsubsection{Data Quality e Cleaning Biografia}
Per quanto riguarda la qualità dei dati delle biografie le principali problematiche sono elencate di seguito:
\begin{enumerate}
	\item Il notebook salva i vari paragrafi delle biografie come una lista di stringhe, quindi prima di tutto la biografia viene trasformata in una stringa, concatenando le varie stringhe presenti nella lista e inserendo un carattere newLine fra un elemento e l'altro.
	\item Inoltre, il notebook  salvava alcuni paragrafi della biografia più volte, per questo motivo prima di concatenare la stringa viene effettuato un controllo per vedere se la porzione di stringa è già stata aggiunta alla stringa finale
	\item Infine, viene fatto un escaping dei caratteri speciali, come ad esempio il carattere "o", in modo da non avere problemi nell'inserimento nel database dei dati.
\end{enumerate}
\subsubsection{Data Quality e Cleaning Relazioni}
Per quanto riguarda la qualità dei dati delle relazioni interpersonali ottenute tramite web scraping, la principale problematica consiste nell'assenza in alcune relazioni del nome del personaggio interessato, ad esempio ci sono relazioni che hanno come nome personaggio "Mother", "Father" e così via.
Per risolvere questo problema il notebook esegue le seguenti operazioni:
\begin{enumerate}
	\item Per ogni personaggio vengono recuperate le relative relazioni.
	\item Per ogni relazione ottenuta viene effettuato un controllo sul nome del personaggio della relazione, se il nome non è presente all'interno della lista di personaggi la relazione viene scartata.
\end{enumerate}
\begin{figure}[H]
  \includegraphics[scale=0.5]{plot_relazioni.png}
  \caption{Grafico relativo alle relazioni tenute rispetto a quelle scartate}
\end{figure}
\subsection{Completezza}
Sono state effettuate altre analisi riguardanti la completezza dei dati, in particolare riguardo ad attributi dei dati ottenuti.
\subsubsection{Dati personaggi}
Le analisi di completezza effettuate sui personaggi consistono nel confronto fra i dati ottenuti dalla web API e quelli ottenuti tramite web scraping. In particolare si può riscontrare una corrispondenza di 323 personaggi della web API con quelli ottenuti tramite web scraping, al netto dei 1559 personaggi della web API.
\begin{figure}[H]
  \includegraphics[scale=0.5]{plot_corrispondenza_personaggi.png}
  \caption{Grafico relativo al numero di personaggi che sono collegabili con i dati ottenuti tramite web scraping.}
\end{figure}
\subsubsection{Descrizione fumetti}
Le analisi di completezza effettuate sulle descrizioni dei fumetti, ottenute tramite web API, consistono nel verificare quanti fumetti possiedono una descrizione. In particolare circa 19000 fumetti non hanno descrizione al netto dei circa 50000 fumetti presenti.
\begin{figure}[H]
  \includegraphics[scale=0.5]{plot_descrizione_fumetti.png}
  \caption{Grafico relativo al numero di fumetti con e senza descrizione.}
\end{figure}
\section{Data Integration}
Per il processo di Data Integration sono state collegate, dove possibile, le due sorgenti dati tramite gli schemi dei personaggi, i quali fungono da punto di incontro fra le due sorgenti dati. È stata realizzata un'operazione di record linkage fra i dati dei personaggi.
\subsection{Data preparation}
In primo luogo si aggiunge una nuova colonna al dataset del web scraping e della web API, contenente il nome del personaggio senza alcuni caratteri particolari come ad esempio "o" e senza qualsiasi porzione di testo racchiusa fra delle parentesi. Queste operazioni sono state effettuate tramite l'utilizzo della libreria python "re", che fa utilizzo delle regular expression per pulire le stringhe. Le parentesi sono tolte per poter fare il confronto dei personaggi senza tenere conto in questo caso della singola variante del personaggio (ad esempio, stesso personaggio di universi differenti). In output si avranno dunque i due schemi relativi ai personaggi con un campo nome processato come detto precedentemente.
\subsection{Schema transformation}
Durante la fase di schema matching è stato effettuato un processo di 'Reverse Engineering' per capire cosa rappresentassero i dati della web API. Tale operazione non è stata fatta per lo scraping, in quanto abbiamo scelto noi quali dati prendere e dunque lo schema era già chiaro a priori.
L'analisi dello schema relativo ai personaggi è così composto:

\begin{enumerate}
	\item Id: identificativo univoco assegnato dall'API ad ogni personaggio.
	\item description: breve descrizione del personaggio.
	\item modified: ultima modifica apportata al personaggio.
	\item thumbnail: URL che porta ad un immagine del personaggio.
	\item comics: lista di fumetti in cui il personaggio è presente, con relativo id fumetto.
	\item series: lista di serie di fumetti in cui il personaggio è presente.
	\item stories: lista di storie in cui il personaggio è presente.
	\item events: lista di eventi in cui ha partecipato il personaggio.
\end{enumerate}

L'analisi dello schema relativo ai fumetti ottenuti tramite web API ha permesso di identificare i seguenti attributi:
\begin{enumerate}
	\item Id: identificativo univoco relativo al fumetto.
	\item title: titolo del fumetto.
	\item description: breve descrizione del fumetto.
	\item modified: ultima modifica dei dati relativi al fumetto.
	\item isbn, upc, diamondCode, ean, issn: identificativi editoriali relativi al fumetto.
	\item forma: formato di stampa del fumetto.
	\item pageCount: numero di pagine del fumetto.
	\item series: lista delle serie a cui appartiene il fumetto.
	\item thumbnail: URL relativa ad un immagine della copertina del fumetto.
	\item images: URL relativi a varie immagini del fumetto.
	\item creators: lista dei creatori del fumetto.
	\item characters: lista di personaggi appartenenti al fumetto.
	\item stories: lista di storie appartenenti al fumetto.
	\item events: lista di eventi significativi presenti nel fumetto.
\end{enumerate}
%\begin{enumerate}
%\item Per ogni personaggio, sia proveniente da scraping che da web API, creo, se non esiste, un nodo <<character>> all'interno del database a grafo, utilizzando come discriminante sull'esistenza il nome processato generato nella fase di schema transformation. Se il nodo esiste già non faccio nulla.
%	\item Per ogni personaggio collego il nodo character corrispondente al nome processato ad un nodo <<character variant>>, che sara creato se non esiste, che è identificato tramite il nome vero e proprio non processato. Se il nodo esiste già procedo aggiungendo le informazioni aggiuntive relative al personaggio. 	
%\end{enumerate}
\subsection{Corrispondences Investigation}
Durante la fase di \textit{Corrispondences Investigation}, si è notato che si possono unire le due basi di dati sulla base dei personaggi, più specificatamente è possibile stabilire un collegamento fra i personaggi sulla base del loro nome. Dopo varie analisi si è notato che, sia nel caso della base di dati ottenuta tramite consultazione della web API sia di quella ottenuta tramite web scraping, un personaggio è identificato tramite un nome privo di parentesi e un'eventuale variante del personaggio è identificata da un nome all'interno della parentesi. Alla luce di queste considerazioni una regola di confronto fra i due schemi consiste nel vedere se due nomi di personaggi sono uguali dopo aver rimosso parentesi ed eventuali testi all'interno delle parentesi.
\subsection{Schemas Integration}
La fase di schemas integration avviene durante l'inserimento dei dati nel database: per tutti i record presenti nei due schemi relativi ai personaggi vengono rimosse le porzioni di stringa contenute all'interno di parentesi tramite l'utilizzo della libreria \textit{re}; in seguito viene creato all'interno del database un nodo di tipo \textit{character} se non è già presente un nodo dello stesso tipo con lo stesso nome.
Al nodo character, sia nel caso in cui sia già stato creato oppure no, viene collegato un nodo \textit{Character Variant} identificato tramite nome completo, ovvero il nome prima della rimozione delle parentesi, contenente tutte le informazioni presenti nel record del personaggio in esame. Ovviamente anche il nodo \textit{Character Variant} viene creato solo qualora non esista già, mentre in caso contrario vengono aggiunte solo le informazioni mancanti presenti nella base di dati da cui proviene il personaggio in esame.
\section{Database}
Il database scelto per lo storage dei dati è un database a grafo. Di seguito elenchiamo i principali motivi che hanno portato alla scelta di questo modello:
\begin{enumerate}
	\item Dati non in real time: la mole di dati riguardante l'universo Marvel non è enorme e non necessita di un inserimento di dati (near)real-time, quindi le operazioni di scrittura sono relativamente poche e le operazioni in lettura sono molte di più; proprio per questo motivo risulta più idoneo l'utilizzo di un database a grafo, in quanto lento in scrittura ma veloce in lettura.
	\item Lo scopo del database è di mostrare le varie relazioni fra i prodotti Marvel e per questo motivo un database a grafo rappresenta la soluzione ideale, in quanto è basato sul concetto di relazioni e collegamenti.
\end{enumerate}
\subsection{Struttura Database}
In questa sezione illustreremo la struttura del database e le sue principali componenti:
\subsubsection{Nodi}
I nodi presenti all'interno del database sono:
\begin{enumerate}
	\item Comic: nodo che rappresenta un singolo fumetto Marvel, con al suo interno il suo id fumetto ottenuto dall'API, i vari codici di identificazione, come ad esempio ISBN, la descrizione del fumetto se è presente, il formato del fumetto e il numero di pagine.
	\item Movie: nodo rappresentante un film Marvel, con al suo interno i vari dati relativi al film come ad esempio la trama del film, i registi, scrittori, produttori, compositori, incassi, durata del film, e data di rilascio del film.
	\item Tv Show: nodo rappresentante una serie tv Marvel, con al suo interno i vari dati relativi al prodotto come ad esempio la trama della prima stagione, i registi, gli showrunner, i produttori e i compositori.
	\item Character: nodo rappresentante la versione generica di un personaggio, contenente al suo interno il nome del personaggio.
	\item Character Variant: nodo che rappresenta una variante precisa di un personaggio, contenente informazioni come ad esempio il nome, una descrizione del personaggio e una biografia del personaggio.
\end{enumerate}
\subsubsection{Relazioni}
Le relazioni presenti fra i nodi all'interno del database sono:
\begin{enumerate}
	\item In Film: relazione che collega un nodo <<Character Variant>> ad un nodo film; rappresenta appunto la partecipazione del personaggio all'interno del film.
	\item In Serie: relazione che collega un nodo <<Character Variant>> ad un nodo Tv Show; rappresenta la partecipazione del personaggio all'interno di una serie tv.
	\item In fumetto: relazione che collega un nodo <<Character Variant>> ad un nodo <<Comic>>; rappresenta la partecipazione del personaggio all'interno di un fumetto.
	\item Conosce: relazione che collega un nodo <<Character Variant>> ad un nodo <<Character Variant>>; rappresenta una relazione inter-personale fra due personaggi.
	\item <<Variante di>>: relazione che collega un nodo di tipo <<character>> ad un nodo di tipo <<character variant>>; rappresenta una variante di un personaggio base.
\end{enumerate}

\subsection{Statistiche database}
All'interno del database sono stati creati in totale $60411$ nodi distribuiti nel seguente modo: 

\begin{center}
\begin{tabular}{||c c||} 
 \hline
 Etichetta Nodo  & Numero Di Nodi \\ [0.5ex] 
 \hline\hline
	
	Character & 4609 \\ \hline 
	Character Variant & 5113 \\ \hline
	Comic & 50607 \\ \hline
	Movie & 43 \\ \hline
	Tv Show & 19 \\ [0.5ex] \hline 
\end{tabular}
\end{center}
Fra i nodi del database sono state create $117763$ relazioni distribuite come di seguito:
\begin{center}
\begin{tabular}{||c c||} 
 \hline
 Etichetta Relazione  & Numero Di Relazioni \\ [0.5ex] 
 \hline\hline
	Conosce & 19040 \\ \hline 
	In Film & 531 \\ \hline
	In Serie & 2405 \\ \hline
	In Fumetto & 90503 \\ \hline
	Variante di & 5284 \\ [0.5ex] \hline 
\end{tabular}
\end{center}
\begin{figure}[H]
  \includegraphics[scale=0.27]{./Figures/comic-variant.png}
  \caption{Visualizzazione di alcuni nodi Character variant (Viola) in relazione a dei nodi Comic (Arancione)}
\end{figure}
\subsection{Alcune Query}
CQL, ovvero Cypher Query Language è il linguaggio di query per interrogare database a grafo, tra cui proprio Neo4j. Cypher è un linguaggio di tipo dichiarativo e pattern-matching, ed inoltre ha una sintassi simile ad SQL.
Grazie alla struttura a grafo del database è possibile ottenere facilmente tramite query relazioni fra i nodi. Ad esempio, potremmo trovare i personaggi conosciuti dal personaggio "Iron Man" e che sono presenti nel film \textit{Avengers}. 
	Per ottenere questo risultato si può utilizzare la seguente query 
	CYPHER: \\\newline \textit{MATCH (i:character\_variant)-[r:conosce]->(c:character\_variant)-[p:in\_film]\\->(m:movie) WHERE i.name = "Iron Man"  AND m.title = "The Avengers" RETURN i,r,c,p,m}
\begin{figure}[H]
  \includegraphics[scale=0.5]{./Figures/query_1.png}
  \caption{Output - Visualizzazione grafica della query}
\end{figure}

In questo secondo esempio invece visualizziamo alcuni fumetti in cui è presente il personaggio "Hulk".
Per ottenere questo secondo risultato si può utilizzare invece la seguente query CYPHER: \\\newline \textit{MATCH (c:character\_variant)-[r:in\_fumetto]->(f:comic) WHERE c.name = "Hulk" RETURN c,f,r LIMIT 100}
\begin{figure}[H]
  \includegraphics[scale=0.5]{./Figures/query_2.png}
  \caption{Output - Visualizzazione grafica della query}
\end{figure}

%----------------------------------------------------------------------------------------
%	RESULTS AND DISCUSSION
%----------------------------------------------------------------------------------------

\section{Conclusione e sviluppi futuri}
In conclusione, abbiamo realizzato un database a grafo partendo dalle due fonti dati, API e web scraping, e successivamente integrato, su cui abbiamo poi svolto una verifica della qualità. Il database finale è completo delle varie relazioni tra personaggi, film e fumetti del mondo Marvel, inoltre ogni nodo contiene diverse informazioni in merito alla sua natura.
Durante lo sviluppo del progetto, abbiamo riscontrato alcune limitazioni o problematiche: abbiamo constatato una lentezza in fase di scrittura del database a grafo, ciò però non risulta un problema limitante in caso di inserimento di pochi dati alla volta, in quanto le operazioni di scrittura sono poche rispetto a quelle di lettura. Inoltre, non tantissimi personaggi hanno un match tra le due fonti di dati, una soluzione potrebbe consistere nell'aggiungere una terza fonte di dati per riuscire ad integrare meglio i dati.
Il database realizzato potrebbe essere utilizzato per implementare sistemi di raccomandazione, oppure per fornire una piattaforma interattiva per appassionati, che consenta loro di scoprire ed esplorare varie relazioni all'interno di questo mondo.
Infine, il database potrebbe essere aggiornato ed ampliato con regolarità, in corrispondenza della produzione di nuovi film, serie tv e fumetti da parte della Marvel Entertainment.

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\renewcommand{\refname}{\spacedlowsmallcaps{References}} % For modifying the bibliography heading

\bibliographystyle{unsrt}

\bibliography{sample.bib} % The file containing the bibliography

%----------------------------------------------------------------------------------------

\end{document}